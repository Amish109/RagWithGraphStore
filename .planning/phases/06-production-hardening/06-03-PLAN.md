---
phase: 06-production-hardening
plan: 03
type: execute
wave: 2
depends_on: ["06-01"]
files_modified:
  - backend/requirements.txt
  - backend/app/config.py
  - backend/app/core/resilience.py
  - backend/app/services/embedding_service.py
  - backend/app/services/generation_service.py
autonomous: true

must_haves:
  truths:
    - "OpenAI calls retry automatically on transient failures"
    - "Circuit breaker prevents cascading failures when OpenAI is down"
    - "Graceful fallback message returned when circuit is open"
  artifacts:
    - path: "backend/app/core/resilience.py"
      provides: "Circuit breaker and retry decorators"
      contains: "@circuit"
    - path: "backend/app/services/embedding_service.py"
      provides: "Embedding service with retry logic"
      contains: "@retry"
    - path: "backend/app/services/generation_service.py"
      provides: "Generation service with circuit breaker"
      contains: "circuit"
  key_links:
    - from: "backend/app/services/embedding_service.py"
      to: "backend/app/core/resilience.py"
      via: "retry decorator import"
      pattern: "from app.core.resilience import"
    - from: "backend/app/services/generation_service.py"
      to: "backend/app/core/resilience.py"
      via: "circuit breaker wrapper"
      pattern: "from app.core.resilience import"
---

<objective>
Implement resilience patterns (circuit breaker and retry with exponential backoff) for external service calls.

Purpose: Prevent cascading failures when OpenAI or other external services are unavailable, and automatically recover from transient network issues without manual intervention.
Output: Robust external service calls that retry on transient failures, circuit-break on sustained failures, and provide graceful degradation.
</objective>

<execution_context>
@/Users/apple/.claude/get-shit-done/workflows/execute-plan.md
@/Users/apple/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-production-hardening/06-RESEARCH.md
@.planning/phases/06-production-hardening/06-01-SUMMARY.md

# Existing files to modify
@backend/app/services/embedding_service.py
@backend/app/services/generation_service.py
@backend/app/config.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add resilience dependencies and configuration</name>
  <files>backend/requirements.txt, backend/app/config.py</files>
  <action>
1. Add to requirements.txt (if not already present):
   - tenacity
   - circuitbreaker

2. Add to config.py Settings class:
   - RETRY_MAX_ATTEMPTS: int = 3
   - RETRY_MIN_WAIT: float = 1.0 (seconds)
   - RETRY_MAX_WAIT: float = 10.0 (seconds)
   - CIRCUIT_FAILURE_THRESHOLD: int = 5 (failures before opening)
   - CIRCUIT_RECOVERY_TIMEOUT: int = 60 (seconds before half-open)
   - RESILIENCE_ENABLED: bool = True (toggle for testing)
  </action>
  <verify>pip install -r backend/requirements.txt; python -c "from app.config import settings; print(settings.CIRCUIT_FAILURE_THRESHOLD)"</verify>
  <done>tenacity and circuitbreaker installed, resilience config accessible</done>
</task>

<task type="auto">
  <name>Task 2: Create resilience module with retry and circuit breaker utilities</name>
  <files>backend/app/core/resilience.py</files>
  <action>
Create backend/app/core/resilience.py with:

1. Imports:
   - tenacity: retry, stop_after_attempt, wait_exponential, retry_if_exception_type, before_sleep_log
   - circuitbreaker: circuit, CircuitBreakerError
   - openai exceptions: APIError, APIConnectionError, RateLimitError, APITimeoutError
   - structlog for logging retries

2. Define TRANSIENT_EXCEPTIONS tuple:
   (APIConnectionError, APITimeoutError, TimeoutError, ConnectionError)
   Note: Do NOT include RateLimitError - that needs different handling (respect Retry-After)

3. Create retry_on_transient decorator factory:
   def retry_on_transient(
       max_attempts: int = None,
       min_wait: float = None,
       max_wait: float = None,
   ):
       """Retry decorator for transient failures with exponential backoff + jitter."""
       return retry(
           stop=stop_after_attempt(max_attempts or settings.RETRY_MAX_ATTEMPTS),
           wait=wait_exponential(
               multiplier=1,
               min=min_wait or settings.RETRY_MIN_WAIT,
               max=max_wait or settings.RETRY_MAX_WAIT,
           ),
           retry=retry_if_exception_type(TRANSIENT_EXCEPTIONS),
           before_sleep=before_sleep_log(structlog.get_logger(), logging.WARNING),
           reraise=True,
       )

4. Create OpenAICircuitBreaker class:
   class OpenAICircuitBreaker:
       """Circuit breaker for OpenAI API calls with graceful fallback."""

       def __init__(self):
           self._circuit = circuit(
               failure_threshold=settings.CIRCUIT_FAILURE_THRESHOLD,
               recovery_timeout=settings.CIRCUIT_RECOVERY_TIMEOUT,
               expected_exception=TRANSIENT_EXCEPTIONS,
           )

       def protected(self, func):
           """Decorator to protect function with circuit breaker."""
           if not settings.RESILIENCE_ENABLED:
               return func
           return self._circuit(func)

       @property
       def is_open(self) -> bool:
           return self._circuit.state == "open"

   # Singleton instance
   openai_circuit = OpenAICircuitBreaker()

5. Create fallback response helper:
   def get_fallback_response() -> str:
       """Return user-friendly message when OpenAI is unavailable."""
       return "I'm temporarily unable to process your request due to high demand. Please try again in a moment."

6. Create CircuitOpenError custom exception for clean handling:
   class CircuitOpenError(Exception):
       """Raised when circuit breaker is open."""
       pass

CRITICAL: Use exponential backoff with jitter (handled by tenacity's wait_exponential).
CRITICAL: Log retries for observability but don't log full request content.
AVOID: Retrying on RateLimitError - respect OpenAI's Retry-After header instead.
  </action>
  <verify>python -c "from app.core.resilience import retry_on_transient, openai_circuit; print('Resilience module loaded')"</verify>
  <done>Resilience module with retry decorator and circuit breaker ready</done>
</task>

<task type="auto">
  <name>Task 3: Apply resilience patterns to embedding and generation services</name>
  <files>backend/app/services/embedding_service.py, backend/app/services/generation_service.py</files>
  <action>
1. Modify backend/app/services/embedding_service.py:
   - Import retry_on_transient from app.core.resilience
   - Import get_logger from app.core.logging
   - Wrap the actual OpenAI embedding call with @retry_on_transient() decorator
   - Add logging on retry attempts

   Example modification to embed_text or similar function:
   ```python
   @retry_on_transient()
   async def _call_openai_embedding(self, text: str) -> list[float]:
       """Internal method with retry protection."""
       response = await self.client.embeddings.create(
           input=text,
           model=settings.OPENAI_EMBEDDING_MODEL,
           dimensions=settings.OPENAI_EMBEDDING_DIMENSIONS,
       )
       return response.data[0].embedding
   ```

2. Modify backend/app/services/generation_service.py:
   - Import retry_on_transient, openai_circuit, get_fallback_response, CircuitOpenError from app.core.resilience
   - Import get_logger from app.core.logging
   - Wrap OpenAI completion calls with both circuit breaker and retry

   Pattern for generation methods:
   ```python
   async def generate_answer(self, query: str, context: list) -> str:
       """Generate answer with circuit breaker and retry protection."""
       logger = get_logger()

       if openai_circuit.is_open:
           await logger.awarning("circuit_open", service="openai")
           return get_fallback_response()

       try:
           return await self._call_openai_completion(query, context)
       except CircuitBreakerError:
           await logger.aerror("circuit_opened", service="openai")
           return get_fallback_response()

   @openai_circuit.protected
   @retry_on_transient()
   async def _call_openai_completion(self, query: str, context: list) -> str:
       """Internal method with circuit breaker and retry protection."""
       # Existing OpenAI call logic
   ```

CRITICAL: Apply circuit breaker OUTSIDE retry decorator (circuit wraps retry, not vice versa).
CRITICAL: Check circuit state BEFORE calling to avoid unnecessary exceptions.
AVOID: Catching all exceptions - only catch transient ones and CircuitBreakerError.
  </action>
  <verify>
1. python -c "from app.services.embedding_service import embed_text; print('Embedding service loads')"
2. python -c "from app.services.generation_service import GenerationService; print('Generation service loads')"
3. Check that services import resilience module correctly
  </verify>
  <done>Embedding service has retry logic, generation service has circuit breaker with fallback</done>
</task>

</tasks>

<verification>
1. Retry behavior test (manual):
   - Temporarily break OpenAI API key
   - Make embedding request
   - Check logs show retry attempts with exponential backoff
   - Restore API key

2. Circuit breaker test (manual):
   - Trigger 5+ consecutive failures
   - Verify circuit opens (returns fallback immediately)
   - Wait recovery_timeout seconds
   - Verify circuit attempts half-open state

3. Code inspection:
   - retry_on_transient only retries TRANSIENT_EXCEPTIONS
   - Circuit breaker wraps retry (not vice versa)
   - Fallback message is user-friendly, not technical
</verification>

<success_criteria>
- Embedding calls retry up to 3 times with exponential backoff on transient failures
- Generation calls protected by circuit breaker (5 failures -> open)
- Circuit breaker returns fallback message when open
- Retry attempts logged with structlog
- RateLimitError not retried (different handling needed)
- Services gracefully degrade rather than crash
</success_criteria>

<output>
After completion, create `.planning/phases/06-production-hardening/06-03-SUMMARY.md`
</output>
