---
phase: 04-langgraph-workflows
plan: 03
type: execute
wave: 2
depends_on: ["04-01", "04-02"]
files_modified:
  - backend/app/workflows/__init__.py
  - backend/app/workflows/state.py
  - backend/app/workflows/nodes/__init__.py
  - backend/app/workflows/nodes/retrieval.py
  - backend/app/workflows/nodes/comparison.py
  - backend/app/workflows/nodes/generation.py
  - backend/app/workflows/document_comparison.py
autonomous: true

must_haves:
  truths:
    - "Document comparison workflow can analyze similarities between documents"
    - "Workflow state persists across requests using checkpointing"
    - "Multi-hop graph reasoning enriches comparison context"
    - "Comparison results include citations from multiple source documents"
  artifacts:
    - path: "backend/app/workflows/state.py"
      provides: "TypedDict state schema for workflows"
      exports: ["DocumentComparisonState"]
    - path: "backend/app/workflows/document_comparison.py"
      provides: "LangGraph document comparison workflow"
      exports: ["create_comparison_workflow", "compare_documents"]
    - path: "backend/app/workflows/nodes/retrieval.py"
      provides: "Retrieval workflow nodes"
      exports: ["retrieve_documents_node", "expand_graph_context_node"]
    - path: "backend/app/workflows/nodes/comparison.py"
      provides: "Analysis workflow nodes"
      exports: ["analyze_comparison_node"]
    - path: "backend/app/workflows/nodes/generation.py"
      provides: "Response generation nodes"
      exports: ["generate_response_node"]
  key_links:
    - from: "backend/app/workflows/document_comparison.py"
      to: "backend/app/db/checkpoint_store.py"
      via: "checkpointer"
      pattern: "get_checkpointer"
    - from: "backend/app/workflows/nodes/retrieval.py"
      to: "backend/app/services/graphrag_service.py"
      via: "graph retrieval"
      pattern: "retrieve_with_graph_expansion"
    - from: "backend/app/workflows/nodes/generation.py"
      to: "backend/app/services/generation_service.py"
      via: "LLM generation"
      pattern: "generate_response"
---

<objective>
Build the LangGraph document comparison workflow with TypedDict state, modular nodes, and PostgreSQL checkpointing.

Purpose: Enable complex multi-step reasoning for document comparison (Success Criteria #1, #4, #5).
Output: Working LangGraph workflow that compares documents and produces analysis with citations.
</objective>

<execution_context>
@/Users/apple/.claude/get-shit-done/workflows/execute-plan.md
@/Users/apple/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/04-langgraph-workflows/04-RESEARCH.md

@backend/app/db/checkpoint_store.py (from 04-01)
@backend/app/services/graphrag_service.py (from 04-02)
@backend/app/services/generation_service.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create workflow state schema and directory structure</name>
  <files>backend/app/workflows/__init__.py, backend/app/workflows/state.py, backend/app/workflows/nodes/__init__.py</files>
  <action>
1. Create workflows/ directory structure:
   - backend/app/workflows/__init__.py (empty)
   - backend/app/workflows/nodes/__init__.py (empty)

2. Create state.py with TypedDict state schema:
   ```python
   from typing import TypedDict, List, Optional

   class DocumentComparisonState(TypedDict):
       """State schema for document comparison workflow."""
       # Input
       query: str
       user_id: str
       document_ids: List[str]

       # Retrieved data
       retrieved_chunks: dict  # {doc_id: [chunk_dicts]}
       graph_context: dict     # {doc_id: [entity_relations]}

       # Analysis results
       similarities: List[str]
       differences: List[str]
       cross_document_insights: List[str]

       # Output
       response: str
       citations: List[dict]  # [{doc_id, chunk_id, text, filename}]

       # Workflow tracking
       status: str
       error: Optional[str]
   ```

NOTE: Use Optional for error field. All other fields have sensible defaults.
  </action>
  <verify>
python -c "from backend.app.workflows.state import DocumentComparisonState; print('State schema OK')"
  </verify>
  <done>workflows/ directory structure exists; state.py defines DocumentComparisonState TypedDict</done>
</task>

<task type="auto">
  <name>Task 2: Create workflow node functions</name>
  <files>backend/app/workflows/nodes/retrieval.py, backend/app/workflows/nodes/comparison.py, backend/app/workflows/nodes/generation.py</files>
  <action>
1. Create retrieval.py:
   - Import retrieve_for_documents from services.retrieval_service
   - Import expand_graph_context from services.graphrag_service

   async def retrieve_documents_node(state: DocumentComparisonState) -> dict:
       """Retrieve chunks from specified documents."""
       retrieved = {}
       for doc_id in state["document_ids"]:
           chunks = await retrieve_for_documents(
               query=state["query"],
               user_id=state["user_id"],
               document_ids=[doc_id],
               max_results=5
           )
           retrieved[doc_id] = chunks.get("chunks", [])
       return {"retrieved_chunks": retrieved, "status": "chunks_retrieved"}

   async def expand_graph_context_node(state: DocumentComparisonState) -> dict:
       """Expand context via multi-hop graph traversal."""
       graph_context = {}
       for doc_id, chunks in state["retrieved_chunks"].items():
           chunk_ids = [c["id"] for c in chunks]
           expanded = await expand_graph_context(chunk_ids)
           graph_context[doc_id] = expanded
       return {"graph_context": graph_context, "status": "graph_expanded"}

2. Create comparison.py:
   - Import generation_service

   async def analyze_comparison_node(state: DocumentComparisonState) -> dict:
       """Analyze similarities and differences using LLM."""
       # Format context for LLM
       context = format_comparison_context(state)

       prompt = f"""Analyze these documents and identify:
       1. Key similarities (3-5 points)
       2. Notable differences (3-5 points)
       3. Cross-document insights (2-3 points)

       Documents:
       {context}

       Query: {state["query"]}

       Return as JSON with keys: similarities, differences, insights"""

       response = await generate_analysis(prompt)
       analysis = parse_analysis_response(response)

       return {
           "similarities": analysis.get("similarities", []),
           "differences": analysis.get("differences", []),
           "cross_document_insights": analysis.get("insights", []),
           "status": "analysis_complete"
       }

   Helper: format_comparison_context(state) -> str:
       Formats retrieved_chunks and graph_context into readable text

3. Create generation.py:
   - Import generate_response from services.generation_service

   async def generate_response_node(state: DocumentComparisonState) -> dict:
       """Generate final comparison response with citations."""
       # Build response from analysis
       response_parts = [
           "## Document Comparison Analysis\n",
           "### Similarities\n" + format_list(state["similarities"]),
           "### Differences\n" + format_list(state["differences"]),
           "### Cross-Document Insights\n" + format_list(state["cross_document_insights"])
       ]

       # Extract citations from retrieved chunks
       citations = extract_citations(state["retrieved_chunks"])

       return {
           "response": "\n".join(response_parts),
           "citations": citations,
           "status": "complete"
       }

   Helper: extract_citations(retrieved_chunks) -> List[dict]:
       Returns list of {doc_id, chunk_id, text, filename} for each chunk used
  </action>
  <verify>
python -c "
from backend.app.workflows.nodes.retrieval import retrieve_documents_node, expand_graph_context_node
from backend.app.workflows.nodes.comparison import analyze_comparison_node
from backend.app.workflows.nodes.generation import generate_response_node
print('All workflow nodes import OK')
"
  </verify>
  <done>All workflow node functions created with single responsibility</done>
</task>

<task type="auto">
  <name>Task 3: Assemble document comparison workflow</name>
  <files>backend/app/workflows/document_comparison.py</files>
  <action>
Create the complete LangGraph workflow:

1. Imports:
   - StateGraph, END from langgraph.graph
   - get_checkpointer from db.checkpoint_store
   - DocumentComparisonState from workflows.state
   - All node functions from workflows.nodes

2. Create async create_comparison_workflow():
   ```python
   async def create_comparison_workflow():
       workflow = StateGraph(DocumentComparisonState)

       # Add nodes
       workflow.add_node("retrieve", retrieve_documents_node)
       workflow.add_node("expand_graph", expand_graph_context_node)
       workflow.add_node("compare", analyze_comparison_node)
       workflow.add_node("generate", generate_response_node)

       # Define flow
       workflow.set_entry_point("retrieve")
       workflow.add_edge("retrieve", "expand_graph")
       workflow.add_edge("expand_graph", "compare")
       workflow.add_edge("compare", "generate")
       workflow.add_edge("generate", END)

       # Compile with checkpointer
       checkpointer = await get_checkpointer()
       return workflow.compile(checkpointer=checkpointer)
   ```

3. Create async compare_documents(
       user_id: str,
       query: str,
       document_ids: List[str],
       session_id: str
   ) -> DocumentComparisonState:
   - Create thread_id as "{user_id}:doc_compare:{session_id}" (Pitfall #5)
   - Build config dict with thread_id
   - Build initial state with empty results
   - Get or create workflow
   - Call workflow.ainvoke(initial_state, config)
   - Return result

CRITICAL: Thread ID MUST include user_id to prevent cross-user state mixing (Pitfall #5).
  </action>
  <verify>
python -c "
from backend.app.workflows.document_comparison import create_comparison_workflow, compare_documents
print('Document comparison workflow imports OK')
"
  </verify>
  <done>document_comparison.py provides working LangGraph workflow with checkpointing</done>
</task>

</tasks>

<verification>
```bash
cd /Users/apple/Desktop/RAGWithGraphStore
python -c "
from backend.app.workflows.state import DocumentComparisonState
from backend.app.workflows.document_comparison import create_comparison_workflow, compare_documents
from backend.app.workflows.nodes.retrieval import retrieve_documents_node
from backend.app.workflows.nodes.comparison import analyze_comparison_node
from backend.app.workflows.nodes.generation import generate_response_node
print('All workflow components import successfully')
"
```
</verification>

<success_criteria>
- DocumentComparisonState TypedDict defines complete state schema
- Node functions are modular with single responsibility
- Workflow uses checkpointer for state persistence
- Thread IDs include user_id for isolation
- Workflow returns citations from multiple documents
</success_criteria>

<output>
After completion, create `.planning/phases/04-langgraph-workflows/04-03-SUMMARY.md`
</output>
