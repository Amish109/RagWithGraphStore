---
phase: 04-langgraph-workflows
plan: 05
type: execute
wave: 3
depends_on: ["04-03", "04-04"]
files_modified:
  - backend/app/api/comparisons.py
  - backend/app/models/schemas.py
  - backend/app/main.py
autonomous: false

must_haves:
  truths:
    - "User can POST to /api/v1/compare with document IDs and query"
    - "Response includes similarities, differences, and cross-document insights"
    - "Response includes citations with specific document sections"
    - "Workflow state persists for multi-turn follow-up queries"
    - "Memory is updated and summarized after comparison interactions"
  artifacts:
    - path: "backend/app/api/comparisons.py"
      provides: "Document comparison API endpoints"
      exports: ["router"]
    - path: "backend/app/models/schemas.py"
      provides: "Request/response schemas for comparison"
      contains: "ComparisonRequest"
  key_links:
    - from: "backend/app/api/comparisons.py"
      to: "backend/app/workflows/document_comparison.py"
      via: "compare_documents"
      pattern: "from.*document_comparison import compare_documents"
    - from: "backend/app/api/comparisons.py"
      to: "backend/app/services/memory_summarizer.py"
      via: "memory integration"
      pattern: "get_memory_summarizer"
    - from: "backend/app/main.py"
      to: "backend/app/api/comparisons.py"
      via: "router include"
      pattern: "include_router.*comparison"
---

<objective>
Create the document comparison API endpoint that integrates the LangGraph workflow with memory summarization.

Purpose: Expose document comparison functionality through REST API (Success Criteria #1, #5).
Output: Working API endpoint for document comparison with citations and persistent workflow state.
</objective>

<execution_context>
@/Users/apple/.claude/get-shit-done/workflows/execute-plan.md
@/Users/apple/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/04-langgraph-workflows/04-RESEARCH.md

@backend/app/workflows/document_comparison.py (from 04-03)
@backend/app/services/memory_summarizer.py (from 04-04)
@backend/app/api/queries.py
@backend/app/models/schemas.py
@backend/app/core/auth.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add comparison schemas to models</name>
  <files>backend/app/models/schemas.py</files>
  <action>
Add Pydantic models for comparison request/response:

1. ComparisonRequest:
   ```python
   class ComparisonRequest(BaseModel):
       """Request schema for document comparison."""
       document_ids: List[str] = Field(
           ...,
           min_length=2,
           max_length=5,
           description="IDs of documents to compare (2-5 documents)"
       )
       query: str = Field(
           ...,
           min_length=10,
           max_length=500,
           description="Comparison query or focus area"
       )
       session_id: Optional[str] = Field(
           default=None,
           description="Session ID for multi-turn conversations"
       )
   ```

2. Citation:
   ```python
   class Citation(BaseModel):
       """Citation from a source document."""
       document_id: str
       chunk_id: str
       filename: str
       text: str = Field(..., max_length=500)
   ```

3. ComparisonResponse:
   ```python
   class ComparisonResponse(BaseModel):
       """Response schema for document comparison."""
       similarities: List[str]
       differences: List[str]
       cross_document_insights: List[str]
       response: str
       citations: List[Citation]
       session_id: str
       status: str
   ```

Import List, Optional from typing; Field from pydantic.
  </action>
  <verify>
python -c "
from backend.app.models.schemas import ComparisonRequest, ComparisonResponse, Citation
req = ComparisonRequest(document_ids=['a', 'b'], query='Compare the main themes')
print(f'Request validates: {req.model_dump()}')
"
  </verify>
  <done>schemas.py contains ComparisonRequest, ComparisonResponse, and Citation models</done>
</task>

<task type="auto">
  <name>Task 2: Create comparison API router</name>
  <files>backend/app/api/comparisons.py</files>
  <action>
Create API router for document comparison:

1. Imports:
   - APIRouter, Depends, HTTPException from fastapi
   - compare_documents from workflows.document_comparison
   - get_memory_summarizer from services.memory_summarizer
   - ComparisonRequest, ComparisonResponse from models.schemas
   - get_current_user from core.auth
   - uuid for session ID generation

2. Create router with prefix="/compare", tags=["comparison"]

3. Implement POST "/" endpoint:
   ```python
   @router.post("/", response_model=ComparisonResponse)
   async def compare_documents_endpoint(
       request: ComparisonRequest,
       current_user: dict = Depends(get_current_user)
   ) -> ComparisonResponse:
       """Compare multiple documents and return analysis with citations."""
       user_id = current_user["sub"]

       # Generate session_id if not provided (new conversation)
       session_id = request.session_id or str(uuid.uuid4())

       try:
           # Execute comparison workflow
           result = await compare_documents(
               user_id=user_id,
               query=request.query,
               document_ids=request.document_ids,
               session_id=session_id
           )

           # Check for workflow errors
           if result.get("error"):
               raise HTTPException(
                   status_code=500,
                   detail=f"Comparison failed: {result['error']}"
               )

           # Update memory with this interaction
           summarizer = get_memory_summarizer()
           await summarizer.add_interaction(
               user_id=user_id,
               query=request.query,
               response=result["response"],
               session_id=session_id
           )

           return ComparisonResponse(
               similarities=result["similarities"],
               differences=result["differences"],
               cross_document_insights=result["cross_document_insights"],
               response=result["response"],
               citations=[Citation(**c) for c in result["citations"]],
               session_id=session_id,
               status=result["status"]
           )

       except Exception as e:
           raise HTTPException(
               status_code=500,
               detail=f"Comparison error: {str(e)}"
           )
   ```

4. Implement GET "/{session_id}/state" endpoint (optional - for debugging):
   ```python
   @router.get("/{session_id}/state")
   async def get_comparison_state(
       session_id: str,
       current_user: dict = Depends(get_current_user)
   ):
       """Get current workflow state for a session (for multi-turn queries)."""
       # This allows clients to check workflow state between turns
       # Implementation retrieves state from checkpointer
       pass  # Placeholder - full implementation if time permits
   ```
  </action>
  <verify>
python -c "
from backend.app.api.comparisons import router
print(f'Comparison router created with {len(router.routes)} routes')
"
  </verify>
  <done>comparisons.py provides POST /compare endpoint with workflow integration</done>
</task>

<task type="auto">
  <name>Task 3: Register comparison router in main app</name>
  <files>backend/app/main.py</files>
  <action>
Update main.py to include the comparison router:

1. Add import:
   ```python
   from app.api.comparisons import router as comparisons_router
   ```

2. Include router after existing routers:
   ```python
   app.include_router(
       comparisons_router,
       prefix=settings.API_V1_PREFIX + "/compare",
       tags=["comparison"]
   )
   ```

3. Verify existing startup/shutdown events include:
   - setup_checkpointer() on startup (from 04-01)
   - close_postgres_pool() on shutdown (from 04-01)
  </action>
  <verify>
python -c "
from backend.app.main import app
routes = [r.path for r in app.routes]
assert any('/compare' in r for r in routes), 'Compare route not found'
print('Comparison router registered in main app')
"
  </verify>
  <done>main.py includes comparison router at /api/v1/compare</done>
</task>

</tasks>

<verification>
```bash
cd /Users/apple/Desktop/RAGWithGraphStore

# Verify all imports
python -c "
from backend.app.api.comparisons import router
from backend.app.models.schemas import ComparisonRequest, ComparisonResponse
from backend.app.main import app
print('All comparison API components import successfully')
"

# Verify routes registered
python -c "
from backend.app.main import app
routes = [r.path for r in app.routes if hasattr(r, 'path')]
compare_routes = [r for r in routes if 'compare' in r]
print(f'Comparison routes: {compare_routes}')
"
```
</verification>

<success_criteria>
- POST /api/v1/compare accepts document_ids and query
- Response includes similarities, differences, cross_document_insights
- Response includes citations with document sections
- Session ID returned for multi-turn conversations
- Memory updated after each comparison interaction
</success_criteria>

<checkpoint type="human-verify">
  <what-built>Document comparison API endpoint with LangGraph workflow integration</what-built>
  <how-to-verify>
1. Start the FastAPI server: `uvicorn backend.app.main:app --reload`
2. Check API docs at http://localhost:8000/docs
3. Verify /api/v1/compare endpoint is listed
4. Test with curl (requires auth token and existing documents):
   ```bash
   curl -X POST http://localhost:8000/api/v1/compare \
     -H "Authorization: Bearer <token>" \
     -H "Content-Type: application/json" \
     -d '{"document_ids": ["doc1", "doc2"], "query": "Compare the main themes"}'
   ```
5. Verify response includes similarities, differences, citations
  </how-to-verify>
  <resume-signal>Type "approved" or describe issues</resume-signal>
</checkpoint>

<output>
After completion, create `.planning/phases/04-langgraph-workflows/04-05-SUMMARY.md`
</output>
